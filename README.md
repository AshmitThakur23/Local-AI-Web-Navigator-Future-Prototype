# Local AI Web Navigator ‚Äî Future Prototype (NexusAI) üöÄü§ñ

[![status: future prototype](https://img.shields.io/badge/status-future%20prototype-orange?style=for-the-badge)](#)
[![TypeScript](https://img.shields.io/badge/TypeScript-97.5%25-3178c6?logo=typescript&logoColor=white&style=for-the-badge)](#)
[![CSS](https://img.shields.io/badge/CSS-1.4%25-264de4?logo=css3&logoColor=white&style=for-the-badge)](#)
[![Other](https://img.shields.io/badge/Other-1.1%25-6e7781?style=for-the-badge)](#)

A refined, UI‚Äëfirst prototype of a privacy‚Äëcentric ‚ÄúLocal AI Web Navigator.‚Äù This repo focuses on product UX, explainability, and rapid iteration in the browser. It ships a demoable front end with model selection, a simulated multi‚Äëpersona video call experience, and a clean path to integrate a local LLM + tools later. ‚ú®

> Recruiter TL;DR: This is a polished, TypeScript/React prototype that demonstrates strong product thinking, UI craft, and a clear migration path from the Python/Playwright implementation to a modular, local‚Äëfirst web agent.

---

# Local AI Web Navigator ‚Äî Future Prototype Demo Photos 

<!-- HERO GALLERY: shows immediately when someone opens the README -->
<p align="center">
  <img alt="Preview 1" src="./Screenshot%202025-10-24%20221838.png" width="31%">
  <img alt="Preview 2" src="./Screenshot%202025-10-24%20221853.png" width="31%">
  <img alt="Preview 3" src="./Screenshot%202025-10-24%20221902.png" width="31%">
</p>
<p align="center">
  <img alt="Preview 4" src="./Screenshot%202025-10-24%20221922.png" width="31%">
  <img alt="Preview 5" src="./Screenshot%202025-10-24%20221931.png" width="31%">
  <img alt="Preview 6" src="./Screenshot%202025-10-24%20221940.png" width="31%">
</p>
<p align="center">
  <img alt="Preview 7" src="./Screenshot%202025-10-24%20222050.png" width="31%">
  <img alt="Preview 8" src="./Screenshot%202025-10-24%20222120.png" width="31%">
  <img alt="Preview 9" src="./Screenshot%202025-10-24%20222131.png" width="31%">
</p>

## What‚Äôs new here compared to the Python repo? üîÅ

This repo: [Local-AI-Web-Navigator-Future-Prototype](https://github.com/AshmitThakur23/Local-AI-Web-Navigator-Future-Prototype)  
Reference repo: [Local-AI-Web-Navigator](https://github.com/AshmitThakur23/Local-AI-Web-Navigator)

- UI-first, TypeScript React app (Vite + Tailwind + shadcn‚Äëui) vs. Python/Flask backend with HTML/CSS/JS.
- Rich ‚ÄúModel Picker‚Äù UX with:
  - Local/Cloud/Downloadable model states, search, keyboard shortcuts, persisted defaults via localStorage.
  - Simulated download flow to communicate scale and modality choices.
- ‚ÄúAI Video Call‚Äù demo (frontend‚Äëonly) with:
  - 6 personas, TTS/STT via Web Speech API, recording simulation, summary/Ask‚ÄëAI, and local persistence.
- Clear demo mode philosophy:
  - Everything labeled as ‚ÄúDemo‚Äù; runs entirely client‚Äëside, no backend dependency to explore flows.
- Modern DX and code quality:
  - ESLint config for TS/React, shadcn component mapping via components.json, Vite entry via index.html ‚Üí /src/main.tsx.

In contrast, the Python repo delivers a production‚Äëleaning backend agent:
- Flask API + Ollama (Mistral) + Playwright automation.
- Live web search and scraping (DuckDuckGo + BeautifulSoup) with priority scoring.
- Product scraper UI with table/gallery, batching, and CSV export.
- Windows one‚Äëclick launchers (.bat/.ps1).

Together, they show both sides: backend capability (Python) and a modern, scalable front‚Äëend experience (this repo) that can later plug into the same local LLM + tools.

---

## Deep dive: files in this repo üîç

These are the key files currently present and what they do.

- README.md (this document)
  - Project overview, demos, architecture, and roadmap.

- README-MODEL-PICKER.md
  - Details a UI‚Äëonly Model Picker:
    - ModelChip inside the search bar (status + tooltip).
    - Modal with Local / Downloadable / Cloud groupings, search/filter, pin-as-default, keyboard navigation.
    - All state persisted in localStorage:
      - `nexus_model_primary` (pinned/default model),
      - `nexus_model_downloaded` (downloaded models).
    - Mocked progress for downloads to visualize large‚Äëmodel UX.
    - No backend calls yet, designed for easy swap‚Äëin of Ollama or API later.

- README-VIDEO-CALL-DEMO.md
  - Frontend‚Äëonly, persona‚Äëdriven video call simulation:
    - Personas: Health Coach, Dietitian, Skincare Expert, Education Tutor, Therapy Assistant, Hustle Coach.
    - Voice: Web Speech API for TTS; STT when available (Chrome/Edge), with graceful text‚Äëinput fallback.
    - Call recording simulation + local summaries and Ask‚ÄëAI across the transcript.
    - All labeled ‚ÄúDemo Mode‚Äù; no server or LLM required.
    - Components sketched: `VideoCallButton`, `CreateCallModal`, `VideoCallScreen`, `RecordingList`, `MeetingSummary`, `personas.ts`.

- index.html
  - Vite entry page. Loads `/src/main.tsx`, sets OpenGraph/Twitter metadata, favicon, and app root.
  - Clear brand surface for shareability and SEO preview.

- eslint.config.js
  - Modern ESLint config with:
    - `@eslint/js`, `typescript-eslint`, `eslint-plugin-react-hooks`, `eslint-plugin-react-refresh`.
    - Targets TS/TSX files, enables React hooks rules, and tolerates constant exports for hot refresh.

- components.json
  - shadcn‚Äëui configuration:
    - Tailwind paths, base color (slate), CSS variables, and alias mapping (components, utils, ui, lib, hooks).
    - Ensures consistent design-system usage across the app.


- Other project metadata
  - The repo is TypeScript‚Äëdominant (97.5%), with Tailwind/shadcn CSS (1.4%), and small ‚ÄúOther‚Äù files (1.1%).
  - Typical Vite projects include `/src` with React components, assets, and routing. `index.html` references `/src/main.tsx`.

---

## Side‚Äëby‚Äëside comparison with the Python repo üß™

| Dimension | Future Prototype (this repo) | Local-AI-Web-Navigator (Python) |
|---|---|---|
| Primary Focus | UX/product prototype, front‚Äëend only | End‚Äëto‚Äëend backend agent with scraping |
| Languages | TypeScript 97.5% | Python 43.8%, JS/HTML/CSS, Batch/PS |
| Runtime | Vite + React + Tailwind + shadcn | Flask API, Playwright, BeautifulSoup, Ollama |
| LLM | Simulated (UI only) | Real local LLM via Ollama (Mistral) |
| Web Automation | Not wired yet (designed for later) | Playwright + DDG search + scraping & scoring |
| Data Persistence | localStorage for demo state | Files (agent_state/*.json), API responses |
| Demos | Model Picker; AI Video Call (personas, TTS/STT, recordings, summaries) | Product Scraper (table/gallery/CSV), Q&A with scoring |
| Launch | npm install ‚Üí npm run dev | One‚Äëclick .bat/.ps1 or manual Python setup |
| Target Users | Product reviewers, recruiters, UX iteration | Power users, developers needing live automation |

What‚Äôs truly new here:
- A polished, explainable UI for model selection, persona‚Äëbased interactions, and demoable voice features.
- Clear separation of concerns so the UI can plug into any local model/tool process later.
- A presentable prototype for non‚Äëengineers to ‚Äúfeel‚Äù the final product, even before wiring a backend.

---

## Architecture vision (how this evolves) üß≠

The plan is to keep all UX/flow in this TypeScript app and inject capabilities over time by attaching local tools (search, click, form‚Äëfill, scrape) and a local LLM backend (Ollama-compatible). The orchestration remains explicit and explainable.

```mermaid
flowchart LR
    U[User] -->|Prompt / Click| UI[React UI (Vite)]
    UI --> C[Controller / State]
    C --> P[Planner / Orchestrator]
    P --> M[(Local LLM)]
    P --> T[Tools: Search ‚Ä¢ Click ‚Ä¢ Extract ‚Ä¢ Summarize]
    T --> W[Web Page]
    T --> E[(Extractors)]
    P --> MM[(Memory)]
    M --> C
    T --> C
    E --> C
    MM --> P
    C --> UI
```

Interaction loop:

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Frontend
    participant C as Controller
    participant P as Planner
    participant T as Toolset
    participant M as Local LLM

    U->>UI: Ask a task (e.g., "Find docs for X")
    UI->>C: Dispatch intent
    C->>P: Build/Refine plan
    P->>M: Suggest next action(s)
    P->>T: Invoke tool (search/extract)
    T-->>C: Results
    C->>UI: Explain step + show result
    UI-->>U: Summary + controls
    loop until done
      P->>M: Next step
    end
```

---

## UI Gallery üì∏

> All images are from the current demo mode. Click to open full size.

| Demo Sequence |
|---|
| ![Repo overview and language stats](Screenshot%202025-10-24%20221838.png) |
| ![Demo session - 1](Screenshot%202025-10-24%20221853.png) |
| ![Demo session - 2](Screenshot%202025-10-24%20221902.png) |
| ![Demo session - 3](Screenshot%202025-10-24%20221922.png) |
| ![Demo session - 4](Screenshot%202025-10-24%20221931.png) |
| ![Demo session - 5](Screenshot%202025-10-24%20221940.png) |
| ![Demo session - 6](Screenshot%202025-10-24%20222050.png) |
| ![Demo session - 7](Screenshot%202025-10-24%20222120.png) |
| ![Demo session - 8](Screenshot%202025-10-24%20222131.png) |

Focused demos:
- Model Picker ‚Üí [README-MODEL-PICKER.md](README-MODEL-PICKER.md)
- Video Call (personas, TTS/STT, recordings) ‚Üí [README-VIDEO-CALL-DEMO.md](README-VIDEO-CALL-DEMO.md)

---

## How to run locally üèÅ

This project is a Vite + React + TypeScript app with Tailwind/shadcn. The current demo also references Firebase Authentication for the `/auth` flow.

1) Configure environment
- Copy `.env.example` to `.env.local` and fill in your Firebase values.
- Enable Google and Email/Password authentication in Firebase.

2) Install and run
```bash
npm install
npm run dev
```

3) Test authentication (demo)
- Visit `/auth`
- Click ‚ÄúContinue with Google‚Äù
- On success, you‚Äôll be redirected to `/`

Security note:
- Do not commit `.env.local`.
- Firebase API key can be public for client usage, but secure the rest with Firebase rules.

---

## Project structure (current snapshot) üóÇÔ∏è

```
/ (root)
‚îú‚îÄ README.md                      # This file
‚îú‚îÄ README-MODEL-PICKER.md         # UI-only model picker demo
‚îú‚îÄ README-VIDEO-CALL-DEMO.md      # Frontend video-call demo
‚îú‚îÄ index.html                     # Vite entry ‚Üí loads /src/main.tsx
‚îú‚îÄ eslint.config.js               # TS/React ESLint rules
‚îú‚îÄ components.json                # shadcn + Tailwind config and aliases
‚îú‚îÄ bun.lockb                      # (present if using Bun tooling)
‚îú‚îÄ .gitignore
‚îî‚îÄ Screenshot *.png               # Demo gallery assets used above
```

> Note: `index.html` references `/src/main.tsx`, which is the Vite/React entrypoint (co-located with app components).

---

## Roadmap üó∫Ô∏è

Near term
- Wire Model Picker to a local LLM runtime (Ollama-compatible endpoint).
- Add pluggable ‚Äútools‚Äù (search, click, extract, summarize) with transparent logs.
- Bring the Product Scraper UX (from Python repo) into this UI with better visual explainability.

Mid term
- Memory layers (short‚Äëterm scratchpad + long‚Äëterm vector store).
- Multi‚Äëmodal inputs (screen understanding, voice I/O), task recipes (‚Äúresearch topic‚Äù, ‚Äúcompare prices‚Äù).
- Session export/share and replayable traces.

Long term
- Full local‚Äëfirst agent loop with safety rails, permission prompts, and granular step control.

---

## Why this design? üí°

- Privacy and control: keep compute on device, reveal every step.
- Velocity: demo features without backend blockers; swap in real LLM/tools later.
- Clarity: personas, model states, and simulated flows help non‚Äëengineers ‚Äúfeel‚Äù the product early.

---

## Contributing ü§ù

Ideas, critiques, and PRs welcome‚Äîespecially:
- Tool adapters (search, click, extract, summarize).
- LLM integration (Ollama, LM Studio, or OpenAI‚Äëcompatible).
- UI overlays for explainability (step traces, diffs, highlights).
- Bringing Python scraper features into this UI.

---

## License üìÑ

License to be finalized. Assume standard evaluation rights for reviewing the prototype.

---

Made with care by AshmitThakur23. ‚ú®
